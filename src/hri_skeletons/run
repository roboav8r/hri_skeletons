#!/usr/bin/env python3
"""
 Copyright (c) 2019 Intel Corporation
               2020 Bristol Robotics Lab, SÃ©verin Lemaignan

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
      http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
"""

import json
import os
import sys
import copy
import subprocess

import uuid

import cv2
import numpy as np

from hri_skeletons.urdf_generator import make_urdf_human
from hri_skeletons.jointstate import compute_jointstate, HUMAN_JOINT_NAMES
from hri_skeletons.modules.inference_engine import InferenceEngine
from hri_skeletons.modules.input_reader import InputReader
from hri_skeletons.modules.draw import Plotter3d, draw_poses
from hri_skeletons.modules.parse_poses import parse_poses

from ikpy import chain
import io # used to wrap the URDF in a file-like object, to be fed to ikpy

import rospy
import rosparam

from sensor_msgs.msg import Image
from sensor_msgs.msg import JointState

from hri_msgs.msg import Skeleton2D, PointOfInterest2D

from cv_bridge import CvBridge, CvBridgeError
from cv_bridge.boost.cv_bridge_boost import getCvType

TOPIC_PREFIX = "humans/bodies/"

def generate_id():
    """ Generates a 5 char long random ID
     'e' are removed to avoid IDs like '12e34' that are interpreted by ROS as 12exp(34), which messes up everything.
    """
    return str(uuid.uuid4())[:5].replace('e','a')


class HumanPoseEstimator3D:
    
    def __init__(self, model, device, height_size, debug=False):

        self.debug = debug

        self.bridge = CvBridge()

        self.body_id_2_pose_id = {}
        self.publishers = {} # maps a body id to its publishers
        self.robot_state_publishers = {} # maps a body id to its robot_state_publisher instance
        self.ik_chains = {} # maps a body id to the IKpy chains
   
        self.stride = 8

        rospy.loginfo("Instanciating the OpenVino inference engine...")
        self.inference_engine = InferenceEngine(model, device, self.stride)
        rospy.loginfo("Done instanciating the OpenVino inference engine")
    
        if self.debug:
   
            self.canvas_3d = np.zeros((720, 1280, 3), dtype=np.uint8)
            self.plotter = Plotter3d(self.canvas_3d.shape[:2])
            self.canvas_3d_window_name = 'Human pose estimation 3D - DEBUG'
            cv2.namedWindow(self.canvas_3d_window_name)
            cv2.setMouseCallback(self.canvas_3d_window_name, Plotter3d.mouse_callback)
    
        extrinsics = {
            "R": [[0.1656794936,0.0336560618,-0.9856051821    ],
                [-0.09224101321,0.9955650135,0.01849052095    ],
                [0.9818563545,0.08784972047,0.1680491765    ]],
            "t": [[17.76193366    ],    [126.741365    ],    [286.3860507    ]]
            }
        self.R = np.array(extrinsics['R'], dtype=np.float32)
        self.t = np.array(extrinsics['t'], dtype=np.float32)
        self.R_inv = np.linalg.inv(self.R)
    
        self.base_height = height_size
        self.fx = -1 # TODO: get that from camera info
    
        self.mean_time = 0

        self.subscriber = rospy.Subscriber("image", Image, self.on_image_cb,  queue_size = 1)
        rospy.loginfo("Waiting for frames")
    
    def rotate_poses(self, poses_3d):
        for pose_id in range(poses_3d.shape[0]):
            pose_3d = poses_3d[pose_id].reshape((-1, 4)).transpose()
            pose_3d[0:3] = np.dot(self.R_inv, pose_3d[0:3] - self.t)
            poses_3d[pose_id] = pose_3d.transpose().reshape(-1)
    
        return poses_3d
    
    def create_body(self, body_id):

        # 1. generate a URDF model for this body, and set it on the
        #    ROS parameter server
        urdf = make_urdf_human(body_id)
        rospy.loginfo("Setting URDF description for body <%s> (param name: human_description_%s)" % (body_id, body_id))
        human_description = "human_description_%s" % body_id
        rosparam.set_param_raw(human_description, urdf)

        urdf_file = io.StringIO(urdf)
        r_arm_chain = chain.Chain.from_urdf_file(urdf_file,
                                                 base_elements=["r_y_shoulder_%s" % body_id],
                                                 base_element_type="joint",
                                                 active_links_mask=[False, True, True, True, True, False])
        urdf_file.seek(0)
        l_arm_chain = chain.Chain.from_urdf_file(urdf_file,
                                                 base_elements=["l_y_shoulder_%s" % body_id],
                                                 base_element_type="joint",
                                                 active_links_mask=[False, True, True, True, True, False])
        urdf_file.seek(0)
        r_leg_chain = chain.Chain.from_urdf_file(urdf_file,
                                                 base_elements=["r_y_hip_%s" % body_id],
                                                 base_element_type="joint",
                                                 active_links_mask=[False, True, True, True, False])
        urdf_file.seek(0)
        l_leg_chain = chain.Chain.from_urdf_file(urdf_file,
                                                 base_elements=["l_y_hip_%s" % body_id],
                                                 base_element_type="joint",
                                                 active_links_mask=[False, True, True, True, False])

        self.ik_chains[body_id] = [r_arm_chain, l_arm_chain, r_leg_chain, l_leg_chain]


        # 2. create the publishers for the 2D skeleton and joint state
        prefix = TOPIC_PREFIX + "%s/" % body_id
        self.publishers[body_id] = [
                rospy.Publisher(prefix + "skeleton2d", Skeleton2D, queue_size=1),
                rospy.Publisher(prefix + "joint_states", JointState, queue_size=1)
                ]

        # 3. spawn a new robot_state_publisher process, which will publish the
        #    TF frames for this body
        rospy.loginfo("Spawning a instance of robot_state_publisher for this body...")
        cmd =["rosrun", "robot_state_publisher", "robot_state_publisher", 
              "__name:=robot_state_publisher_body_%s" % body_id,
              "joint_states:=%s" % (prefix + "joint_states"),
              "robot_description:=%s" % human_description,
              "_publish_frequency:=25",
              "_use_tf_static:=false"
              ]
        rospy.loginfo("Executing: %s" % " ".join(cmd))
        proc = subprocess.Popen(cmd,
                          stdout=sys.stdout,
                          stderr=subprocess.STDOUT)
        self.robot_state_publishers[body_id] = proc

    def delete_body_id(self, body_id):
        rospy.loginfo("Removing body <%s>..." % body_id)
        for p in self.publishers[body_id]:
            p.unregister()
        del self.publishers[body_id]

        self.robot_state_publishers[body_id].terminate()
        del self.robot_state_publishers[body_id]


        del self.ik_chains[body_id]


    def make_2d_skeleton_msg(self, original_image, pose_2d):
        skel = Skeleton2D()
        skel.header = copy.copy(original_image.header)

        # OpenVINO 2D keypoint order:
        # ['neck', 'nose',
        #   'l_sho', 'l_elb', 'l_wri', 'l_hip', 'l_knee', 'l_ank',
        #   'r_sho', 'r_elb', 'r_wri', 'r_hip', 'r_knee', 'r_ank',
        #   'r_eye', 'l_eye',
        #   'r_ear', 'l_ear']

        skel.skeleton = [None] * 18

        openvino_ordered_kpt = [PointOfInterest2D(x=x, y=y, c=c) for x,y,c in pose_2d]

        skel.skeleton[Skeleton2D.NECK] =           openvino_ordered_kpt[0]
        skel.skeleton[Skeleton2D.NOSE] =           openvino_ordered_kpt[1]
        skel.skeleton[Skeleton2D.LEFT_SHOULDER] =  openvino_ordered_kpt[2]
        skel.skeleton[Skeleton2D.LEFT_ELBOW] =     openvino_ordered_kpt[3]
        skel.skeleton[Skeleton2D.LEFT_WRIST] =     openvino_ordered_kpt[4]
        skel.skeleton[Skeleton2D.LEFT_HIP] =       openvino_ordered_kpt[5]
        skel.skeleton[Skeleton2D.LEFT_KNEE] =      openvino_ordered_kpt[6]
        skel.skeleton[Skeleton2D.LEFT_ANKLE] =     openvino_ordered_kpt[7]
        skel.skeleton[Skeleton2D.RIGHT_SHOULDER] = openvino_ordered_kpt[8]
        skel.skeleton[Skeleton2D.RIGHT_ELBOW] =    openvino_ordered_kpt[9]
        skel.skeleton[Skeleton2D.RIGHT_WRIST] =    openvino_ordered_kpt[10]
        skel.skeleton[Skeleton2D.RIGHT_HIP] =      openvino_ordered_kpt[11]
        skel.skeleton[Skeleton2D.RIGHT_KNEE] =     openvino_ordered_kpt[12]
        skel.skeleton[Skeleton2D.RIGHT_ANKLE] =    openvino_ordered_kpt[13]
        skel.skeleton[Skeleton2D.RIGHT_EYE] =      openvino_ordered_kpt[14]
        skel.skeleton[Skeleton2D.LEFT_EYE] =       openvino_ordered_kpt[15]
        skel.skeleton[Skeleton2D.RIGHT_EAR] =      openvino_ordered_kpt[16]
        skel.skeleton[Skeleton2D.LEFT_EAR] =       openvino_ordered_kpt[17]
 
        return skel

    def make_jointstate(self, body_id, original_image, pose_3d):

        js = JointState()

        js.header = copy.copy(original_image.header)

        js.name = [jn + "_%s" % body_id for jn in HUMAN_JOINT_NAMES]

        js.position = compute_jointstate(self.ik_chains[body_id], pose_3d)

        return js

    def publish(self, body_id, original_image, poses_3d, poses_2d):

        pose_3d = poses_3d[self.body_id_2_pose_id[body_id]]
        pose_2d = np.array(poses_2d[self.body_id_2_pose_id[body_id]][0:-1]).reshape((-1, 3))

        skel = self.make_2d_skeleton_msg(original_image, pose_2d)

        jointstate = self.make_jointstate(body_id, original_image, pose_3d)

        skel_pub, jointstate_pub = self.publishers[body_id]

        skel_pub.publish(skel)
        jointstate_pub.publish(jointstate)

    def on_image_cb(self, data):

        rospy.loginfo_once("Got first frame! Starting skeleton detection")

        try:
            frame = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            rospy.logerr(e)
            return
    
        current_time = cv2.getTickCount()
        input_scale = self.base_height / frame.shape[0]
        scaled_img = cv2.resize(frame, dsize=None, fx=input_scale, fy=input_scale)
    
        if self.fx < 0:  # Focal length is unknown
            self.fx = np.float32(0.8 * frame.shape[1])
    
        inference_result = self.inference_engine.infer(scaled_img)
    
        poses_3d, poses_2d = parse_poses(inference_result, input_scale, self.stride, self.fx, is_video = True)
    
        ####################
        # Poses 3D
        #
        # Poses are returned by OpenVINO as a set of 
        # keypoints in the following order:
        #
        # 00 torso
        # 01 head (sellion)
        # 02 ? (nose?)
        # 03 l_shoulder
        # 04 l_elbow
        # 05 l_wrist
        # 06 l_hip
        # 07 l_knee
        # 08 l_ankle
        # 09 r_shoulder
        # 10 r_elbow
        # 11 r_wrist
        # 12 r_hip
        # 13 r_knee
        # 14 r_ankle
        # 15 l_eye
        # 16 l_ear
        # 17 r_eye
        # 18 r_ear
        #

        edges = []
        if len(poses_3d) > 0:

            poses_3d = self.rotate_poses(poses_3d)
            poses_3d_copy = poses_3d.copy()
            x = poses_3d_copy[:, 0::4]
            y = poses_3d_copy[:, 1::4]
            z = poses_3d_copy[:, 2::4]
            poses_3d[:, 0::4], poses_3d[:, 1::4], poses_3d[:, 2::4] = -z, x, -y
    
            poses_3d = poses_3d.reshape(poses_3d.shape[0], 19, -1)[:, :, 0:3]
            edges = (Plotter3d.SKELETON_EDGES + 19 * np.arange(poses_3d.shape[0]).reshape((-1, 1, 1))).reshape((-1, 2))
 
            last_nb_bodies = len(self.body_id_2_pose_id)
            if len(poses_3d) != last_nb_bodies: # one body has appeared or disappeared! We have to re-assign ids for everyone
                for body_id in list(self.body_id_2_pose_id.keys()):
                    self.delete_body_id(body_id)
                    del self.body_id_2_pose_id[body_id]

                for pose_id, pose in enumerate(poses_3d):
                    body_id = generate_id()
                    self.body_id_2_pose_id[body_id] = pose_id
                    self.create_body(body_id)

            for body_id in self.body_id_2_pose_id.keys():

                self.publish(body_id, data, poses_3d, poses_2d)

       
        if self.debug:
            self.plotter.plot(self.canvas_3d, poses_3d, edges)
        
            draw_poses(frame, poses_2d)
            current_time = (cv2.getTickCount() - current_time) / cv2.getTickFrequency()
            if self.mean_time == 0:
                self.mean_time = current_time
            else:
                self.mean_time = self.mean_time * 0.95 + current_time * 0.05
            cv2.putText(frame, 'FPS: {}'.format(int(1 / self.mean_time * 10) / 10),
                        (40, 80), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255))
            
            cv2.imshow(self.canvas_3d_window_name, self.canvas_3d)
            cv2.imshow('3D Human Pose Estimation - DEBUG', frame)
            cv2.waitKey(10)
    



if __name__ == '__main__':
    
    rospy.init_node("hri_skeletons")

    # link to the XML file containing the OpenVINO model for 3D human pose estimation
    # https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/human-pose-estimation-3d-0001/description/human-pose-estimation-3d-0001.md
    model = rospy.get_param("~model")

    # one of: CPU, GPU, FPGA, HDDL or MYRIAD. '
    device = rospy.get_param("~device", "CPU")

    # Network input layer height size.
    height_size = rospy.get_param("~height_size", 256)

    # if true, display a 3D canvas with the skeletons
    debug = rospy.get_param("~debug", False)
    if debug:
        rospy.logwarn("Debugging mode ON")

    estimator = HumanPoseEstimator3D(model, device, height_size, debug)

    try:
        rospy.spin()
    except KeyboardInterrupt:
        rospy.loginfo("Shutting down")
        cv2.destroyAllWindows()
